---
title: "四、NVIDIA的铲子:CUDA的出现"
date: 2025-12-4
tags: [历史]
comments: true
---

<div class="lang-zh">

<!-- more -->

1993年，黄仁勋、克里斯·马拉科夫斯基和柯蒂斯·普里姆创立NVIDIA。他们的初衷是为PC游戏开发高性能图形处理器。当时的市场中产品性能平庸且同质化严重，3D图形则几乎是空白。NIVIDA最初是想在显卡上占据一席之地，但随着CUDA的出现，GPU的高算力特性开始显现，成为了AI计算的核心工具。常言道“时势造英雄”，NIVIDA误打误撞驶向了AI这条车道，最终成就了一个历史上空前的商业帝国。

# CUDA之前的NIVIDA

最开始，NIVIDA在图形处理方面使用的技术是二次曲面纹理映射，即用二次方程来构建和渲染3D模型。相比当时主流（但尚未普及）的多边形（三角形）渲染，它在理论上可以用更少的数据描述更复杂的曲面。NIVIDA相信它能为PC游戏开发者提供一套高性能、低成本的一站式解决方案。但事实证明，NIVIDA做了一个错误的赌注。第一款产品是NV1以及其后续NV2接连失败，使得公司陷入绝境，濒临破产。好在世嘉支付了700万美元的研发预付款，这成为了NVIDIA的救命钱。

NIVIDA的创建一波三折，最后艰难存活，它懂得了一个道理，技术路线必须顺应开放生态标准，而非自创孤岛。（放在现在也仍是这样，脱离开放的生态标准，技术很难找到应用对象，也不具有旺盛的生命力）

时间来到世纪之交，1997年，NIVIDA推出RIVA 128，完全支持行业标准DirectX和OpenGL，凭借性能与兼容性一炮而红，成为企业发展的转折点。1999年，发布GeForce 256。它是史上第一款被称为 GPU 的芯片，引入 硬件T&L（变换与光照），将CPU的部分工作转移至GPU，开启了GPU专用图形计算时代。2001-2003年，GeForce 3和FX系列引入可编程顶点与像素着色器，GPU从“固定功能”变为“可编程处理器”，灵活性大增。与早期的Microsoft神似，NIVIDA在与ATI的激烈竞争中，逐渐成为消费级图形市场的霸主。

2006年，一个革命性的架构诞生了。G80架构（GeForce 8800 GTX）横空出世，采用128个统一的流处理器。它在硬件上本质上已是一个强大的通用并行计算阵列，只是当前任务被设定为图形渲染。G80为通用计算准备好了“完美的身体”，只等一个“灵魂”（软件模型）来激活它————CUDA。

# CUDA

2000年左右，伊恩·巴克在斯坦福大学攻读博士学位期间，就在研究如何让图形硬件（GPU）更易于编程，用于通用计算。这让他站在了“GPGPU”思想（General-Purpose computing on Graphics Processing Units）的最前沿。2004年，当NVIDIA管理层（尤其是黄仁勋）开始认真思考GPU计算潜力时，巴克作为这个领域的顶尖人才被主动招募进NVIDIA研究院。他的任务非常明确：为NVIDIA的GPU创造一个真正的通用计算编程模型。

在CUDA之前，包括巴克在内的科学家们已经通过“通用GPU计算”借用显卡算力，但过程极其痛苦。他们必须把科学计算问题（如模拟蛋白质折叠）伪装成渲染三角形和纹理的图形问题，不仅编程复杂，且效率低下。巴克团队的目标就是终结这种“扭曲”的编程方式。团队的构想需要强大的硬件基础。幸运的是，NVIDIA当时正在由首席科学家大卫·柯克领导的架构团队，秘密开发代号为 “费米” 的下一代GPU。这个架构（后定名为 G80）的革命性在于统一着色器架构：处理器不再专用于顶点或像素，而是变成了一组通用的、可编程的流处理器。而且为线程并行而生：硬件设计上就能高效管理和切换成千上万个并行线程。当巴克团队看到G80的设计时，他们意识到硬件已经准备好了。这个芯片本质上就是一个强大的并行计算引擎，只是之前被“图形处理器”的名字所束缚。

因此，巴克的计算团队与柯克的GPU架构团队进行了前所未有的深度合作：架构团队根据计算编程的需求，在G80中加入了关键电路，比如用于线程快速同步的共享内存、更通用的指令集等。G80是第一款为运行C语言程序而设计了硬件电路的GPU。巴克团队则基于这些硬件特性，设计CUDA的编程模型——如何组织线程网格、如何管理内存层次。他们创造了一个能让程序员用标准C语言，直观地控制成千上万个并行线程的模型。CUDA与NIVIDA的GPU硬件实现了“人机合一”，仿佛大脑与身体一般，二者精妙、紧密地联系在一起，爆发出前所未有的计算潜力！CUDA可谓是专为GPU而生，而现行GPU也仿佛专门为CUDA而造。

2006年初，项目进入最后阶段。技术已基本成型，需要一个响亮的名字。团队考虑过“Compute Unified Device Architecture”的缩写，但最终简化为更具冲击力的CUDA——取自西班牙语“锋利”之意，寓意将GPU的计算潜力“磨利”。同年夏天，第一款搭载G80架构的显卡GeForce 8800 GTX完成流片。当第一块工程样品送到巴克实验室时，团队屏息以待。他们编写了第一个真正的CUDA程序——不是渲染三角形，而是直接计算质数序列。当屏幕上正确显示出计算结果时，实验室爆发了欢呼。一位团队成员后来回忆：“那一刻，我们知道自己不仅创造了一个工具，而是开启了一个新时代。GPU终于可以向程序员敞开自己的全部能力，无需任何图形伪装的中间层。”

2006年11月8日，发布会如期举行。黄仁勋在舞台上展示了CUDA的三大支柱：C语言编程接口、并行线程执行(PTX)虚拟机和强大的计算库。他现场演示了用CUDA加速医学图像处理和流体模拟，速度比当时的顶级CPU快上百倍。《纽约时报》次日的报道标题写道：“显卡制造商宣称计算机科学新篇章”，字里行间仍带着技术记者惯有的审慎怀疑。他们无法预见的是，这场发布会点燃的火把，将在六年后照亮整个人工智能的黎明。

# CUDA之后的NIVIDA：AlexNet前

在今天看来，CUDA的出现几乎是整个AI发展史上最重要的一环，可以说，没有CUDA就没有后面的一切，它的重要性怎么强调都不为过。它不单单塑造了当前世界市值最高的公司，还使得算力爆炸式地增长，真正地开启了人类的“大计算时代”。笔者愿意将CUDA的出现，比作蒸汽机的诞生，没有它，就没有往后恢弘的历史篇章。

然而在CUDA诞生到2012AlexNet之前，行业、社区还没有看到并行运算的潜力。就NIVIDA来说，最初的G80架构虽支持CUDA，但设计初衷仍是图形，真正为严肃计算打造专用引擎，要到2010年的Fermi架构，这才是第一款真正为通用计算而生的GPU架构。CUDA问世之初，外界充满质疑。游戏玩家觉得它无用，华尔街认为NVIDIA偏离了赚钱的显卡主业，是在烧钱追逐一个虚无缥缈的“科学计算”市场。

但NIVIDA做好了布局。

它持续优化CUDA编译器、调试器和性能分析工具，让编程更高效。推出高度优化的 cuBLAS（线性代数库）和 cuFFT（快速傅里叶变换库）。科学家无需重写算法，简单调用即可获得百倍加速，这成为吸引早期采用者的关键。启动 “CUDA教学中心” 计划，向全球顶尖大学捐赠GPU计算套件和教材。从麻省理工到剑桥，一代理工科学生开始学习CUDA编程。这步棋至关重要，它确保了未来十年，全球顶尖实验室和公司的研发人员，其第一思维惯性就是CUDA。NVIDIA做了一件至关重要的事：默默修建了一条名为“CUDA”的高速公路，并确保路上有加油站、指示牌和驾驶学校。我们将看到，在即将到来的计算革命后，CUDA变成了通往人工智能未来的 “唯一主干道” 。

<br>

CUDA的出现，可谓是惊天动地的一件事。我们现在生活、研究中的很多方面都离不开CUDA。在AI的淘金热中，NIVIDA正是凭借它，成为了那个唯一的、买铲子的人。

## ps:CUDA简介

### CUDA本质是拓展的C++

CUDA本质上是一个拓展的C++语言，它继承了大部分的C++语言的内容，同时具有自己的独特内容，下面就是一个简单的.cu文件：

(图片)

其中main函数、printf等都是C++的老熟人，而“__global__ void……”、“helloFromGPU<<<2,3>>>()”则是CUDA的特定语言。

值得一提的是，现在一般情况下，AI工作者不会直接适用CUDA C++来编程。原因是，由于C++的特性，在实际工作中，CUDA文件会非常非常复杂，成千上万行代码非常难以维护，稍有不慎就会发生严重的后果……所有，在CUDA C++的基础上还有一系列更高级的语言，比如现在常用的Triton、CUDA Tile,它们本质上是python文件，以.py形式保存，但是在运行是，它们自己的特定编译器会将高级的语言转化成更低级、复杂的CUDA C++语言，生成一个中间的.cu文件，再送去编译。

### CUDA的编译

当我们有了一个用CUDA C++写好的.cu文件后，我们要拿给电脑运行，生成.exe文件。这个过程相较于C++程序的编译就要复杂多了。

最开始，你需要下载CUDA ToolKit，这是一个开发工具包，里面装有：nvcc，一个编译器驱动；ptxas，一个汇编器，用于生成SASS汇编代码；还有其他工具。开始编译后，nvcc会将你的.cu程序拆解，得到只含有C++部分的.cpp文件，和一个含有CUDA语法的.ptx文件。

.cpp文件方面就与我们普通的.cpp文件没两样了，拿给你电脑上自带的C++编译器编译，生成.s文件，如果是windows系统就再拿给自带的x86汇编器如MSVC汇编成机器码.obj文件，连接器连接多个.obj文件后形成.exe文件。

在.ptx方面，有时我们不会直接编译它（原因在后面），需要编译时，会使用ptxas.exe这个汇编器，将.ptx文件转化为NIVIDA GPU能读懂的用SASS机器码写成的.cubin文件，最后，我们会汇合.exe与.cubin文件，作为最后的可执行文件，给电脑运行。.exe部分负责CPU的工作，.cubin部分负责GPU的工作。

当我们想应用别人写好的CUDA程序（就是那个最后的可执行文件）时，情况也有稍稍不同。首先，你得安装NIVIDA的驱动程序，这里面装有一个JIT.exe文件，也是一个汇编器。当你的文件没有.ptx，只有.cubin时，JIT不运行，直接输给机器。当含有.ptx时，JIT会将.ptx编译成.cubin文件，再给电脑运行。

你可能想问，为什么要这么做？为什么有时要使用.ptx文件，而不是.cubin机器码？因为不同的GPU型号,对应的SASS机器码不同，在A100上适配的.cubin文件，在H100上运行不了。但是.ptx是不变的，它记录着使用GPU的思路，所以2016年写的.ptx在2026年的机器经过JIT编译后上一样能跑。这样就实现了代码在不同机器间的迁移，是一个天才的idea!

### CUDA的严格闭源

CUDA作为NIVIDA最重要的护城河，实现了严格的闭源。像Intel的x86架构，是完全的开源，从汇编器到指令集，都完全透明，以至于现在的大学生在大二上学期的计算机组成课上就可以直接用x86的汇编语言写程序（悲），而CUDA则是完全闭源。问题的核心就在于上文提到的那两个编译器，ptxas与JIT，NIVIDA从未公开过它们的代码实现，仅仅是提供了.exe文件（就像windows不会公开自己的操作系统源代码，装在你电脑磁盘里的都是.exe文件），所有，没人知道汇编时发生了什么，怎么发生的。虽然，我们可以通过检测反向推断出编译器的实现（这是完全可能的），但一但你这么做，就会立即被NIVIDA起诉……通过开发者与用户端的双重保险，NIVIDA在CUDA生态中起到了绝对的控制作用。着也无可厚非，毕竟CUDA是人家NIVIDA的专利与起家的老本。

### CUDA的应用与更新

很多AI初学者一开始往往意识不到CUDA的在自己研究中的重要性。我们一般就会打开VScode，import torch，然后就开始写Nerual Network，训练、调参……事实也确实是如此，TensorFlow、PyTorch这些框架已经替我们完成了写CUDA C++这一痛苦的步骤。它们会自动将与GPU打交道的部分转化为CUDA C++语言，所以在我们看来，完全不用担心自己写.cu程序，PyTorch已经帮你做了！确实，DeepLearning框架的出现拯救了无数AI从业者的时间，遥想在2012年，Alex在编写AlexNet时，就是手动写CUDA C++程序，把CNN放在GPU上跑，其辛苦可想而知。但是现在，在开发新模型时，与CUDA打交道是绝对无法避免的。因为你自己提出来的算法，在pytorch上面根本就没有！（比如你想了一个新的运算叫“超卷积”，但是PyTorch上没有这个工具！）这时候，就需要你自己用python将它实现出来。如果你想用这个新算法训练模型，就必须要手动在CUDA上配置！以Mamba模型为例，团队领袖之一的Tri Dao自己就是一个GPU专家，正是它将模型在GPU上高效实现，才造就了Mamba模型的性能。甚至，有时一个模型想法很好，但是在CUDA上实现得很差，效果也不会理想！因此不光是在python上得优化，在CUDA上得优化对于研究同样重要！

值得一提的是，CUDA自发布经历了数次更新，截至今天（12月6日），CUDA已经发展到13.1版本。12月6日，笔者正在写作这篇文章时，CUDA发布了“自2006年CUDA诞生以来，最重大的更新”，CUDA推出了CUDA tile，与Triton类似，也是一个高级的框架。CUDA Tile可谓是划时代的，因为它极大地简化了编程语言的书写，矩阵运算不用再写复杂的循环，也不用自己手动分配内存，现在只需def matrix_mul_tiled(A_tile, B_tile):return tile_matmul(A_tile, B_tile)，编译器就会自动的帮你分配线程、内存，而且这些分配是最优的。CUDA编写者的时间再一次得到解放，以前几百行的代码，现在几十行就可以解决。对于研究者来说，现在对CUDA的编写就像是从写C++变到了写python，这无疑是一件幸福的事！(*^_^*)
</div>
